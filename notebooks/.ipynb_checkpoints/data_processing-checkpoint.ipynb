{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataProcessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Import your dataset\n",
    "def load_dataset(path):\n",
    "    # Automatically detect file type\n",
    "    if path.endswith('.csv'):\n",
    "        df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "    elif path.endswith('.parquet'):\n",
    "        df = spark.read.parquet(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Use CSV or Parquet.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "dataset_path = \"/workspace/data/your_dataset.csv\"\n",
    "spark_dataframe = load_dataset(dataset_path)\n",
    "\n",
    "# Show basic information\n",
    "spark_dataframe.printSchema()\n",
    "spark_dataframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
