{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac51f72-0180-4d0c-9df1-477beb4a1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "from pyspark.sql.functions import col, regexp_replace, trim, when, regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, isnan, when, count ,date_format,to_date,to_timestamp\n",
    "\n",
    "\n",
    "from pyspark.sql import (\n",
    "    DataFrame,\n",
    "    SparkSession,\n",
    ")\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    datediff,\n",
    "    lit,\n",
    "    regexp_replace,\n",
    "    round,\n",
    "    to_date,\n",
    "    trim,\n",
    "    upper,\n",
    "    when,\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Orderlines  DataProcessing\") \\\n",
    "    .getOrCreate()\n",
    "#Customers Schema\n",
    "order_lines_schema = StructType(\n",
    "        [\n",
    "            StructField(\"ORDER_ID\", StringType(), True),\n",
    "            StructField(\"PRODUCT_ID\", StringType(), True),\n",
    "            StructField(\"ORDER_QTY\", FloatType(), True),\n",
    "            StructField(\"AGREED_DELIVERY_DATE\", StringType(), True),\n",
    "            StructField(\"ACTUAL_DELIVERY_DATE\", StringType(), True),\n",
    "            StructField(\"DELIVERY_QTY\", StringType(), True),\n",
    "        ]) \n",
    "\n",
    "# Reading Customer CSV\n",
    "df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(order_lines_schema) \\\n",
    "    .load(\"../data/order_lines.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc15c585-c6f8-449c-8150-3445b9d14d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers DataFrame Schema:\n",
      "root\n",
      " |-- ORDER_ID: string (nullable = true)\n",
      " |-- PRODUCT_ID: string (nullable = true)\n",
      " |-- ORDER_QTY: float (nullable = true)\n",
      " |-- AGREED_DELIVERY_DATE: string (nullable = true)\n",
      " |-- ACTUAL_DELIVERY_DATE: string (nullable = true)\n",
      " |-- DELIVERY_QTY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schemas\n",
    "print(\"Customers DataFrame Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f506b6-1359-44a3-807e-1bdaa6800dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "|   ORDER_ID|PRODUCT_ID|ORDER_QTY|AGREED_DELIVERY_DATE|ACTUAL_DELIVERY_DATE|DELIVERY_QTY|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "|FMR34203601|  25891601|    110.0|Friday, March 4, ...|Friday, March 4, ...|         110|\n",
      "|FMR32320302|  25891203|    347.0|Wednesday, March ...|Wednesday, March ...|         347|\n",
      "|FMR33320501|  25891203|    187.0|Thursday, March 3...|Thursday, March 3...|         150|\n",
      "|FMR34220601|  25891203|    235.0|Friday, March 4, ...|Friday, March 4, ...|         235|\n",
      "|FMR33703603|  25891203|    176.0|Thursday, March 3...|Thursday, March 3...|         176|\n",
      "|FMR33721603|  25891203|    345.0|Thursday, March 3...|Thursday, March 3...|         345|\n",
      "|FMR33420203|  25891203|    138.0|Thursday, March 3...|Sunday, March 6, ...|         138|\n",
      "|FMR34420402|  25891203|    381.0|Friday, March 4, ...|Saturday, March 5...|         381|\n",
      "|FMR32403401|  25891203|    348.0|Wednesday, March ...|Wednesday, March ...|         348|\n",
      "|FMR34121203|  25891203|    480.0|Friday, March 4, ...|Sunday, March 6, ...|         480|\n",
      "|FMR32501601|  25891203|    478.0|Wednesday, March ...|Wednesday, March ...|         478|\n",
      "|FMR34501203|  25891203|    491.0|Friday, March 4, ...|Friday, March 4, ...|         491|\n",
      "|FMR34102602|  25891203|    407.0|Friday, March 4, ...|Friday, March 4, ...|         387|\n",
      "|FMR33902203|  25891203|   -299.0|Thursday, March 3...|Thursday, March 3...|         299|\n",
      "|FMR34903603|  25891203|    329.0|Friday, March 4, ...|Friday, March 4, ...|         329|\n",
      "|FMR32421203|  25891203|   -441.0|Wednesday, March ...|Thursday, March 3...|         419|\n",
      "|FMR33421203|  25891203|    104.0|Thursday, March 3...|Sunday, March 6, ...|          99|\n",
      "|FMR33402203|  25891203|    491.0|Thursday, March 3...|Saturday, March 5...|         491|\n",
      "|FMR33621603|  25891203|   -138.0|Thursday, March 3...|Thursday, March 3...|         138|\n",
      "|FMR34520301|  25891203|    172.0|Friday, March 4, ...|Friday, March 4, ...|         155|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_lines_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fbe133a-1ef8-4218-ba17-7cd4fabac9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_order_qty_and_delivery_qty(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean ORDER_QTY and DELIVERY_QTY columns.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\"ORDER_QTY\", col(\"ORDER_QTY\").cast(IntegerType()))\n",
    "        .withColumn(\"DELIVERY_QTY\", regexp_replace(col(\"DELIVERY_QTY\"), r\"[^0-9]\", \"\"))\n",
    "        .withColumn(\"DELIVERY_QTY\", col(\"DELIVERY_QTY\").cast(IntegerType()))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df52b5c-9af7-42e2-9359-d7615d736126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_invalid_quantities(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Filter out rows with invalid quantities.\"\"\"\n",
    "    return df.filter((col(\"ORDER_QTY\") > 0) & (col(\"DELIVERY_QTY\") > 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "308eb909-a2e2-4053-a706-8d8941be42c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_agreed_delivery_date(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and parse AGREED_DELIVERY_DATE column.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"AGREED_DELIVERY_DATE\"), r\"[^a-zA-Z0-9/,-]\", \"\"\n",
    "            ),  # Remove special characters\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"AGREED_DELIVERY_DATE\"), r\"\\d{4}\", \"2024\"\n",
    "            ),  # Replace any year with 2024\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            when(\n",
    "                to_date(col(\"AGREED_DELIVERY_DATE\"), \"MM/dd/yyyy\").isNotNull(),\n",
    "                to_date(col(\"AGREED_DELIVERY_DATE\"), \"MM/dd/yyyy\"),\n",
    "            )\n",
    "            .when(\n",
    "                to_date(col(\"AGREED_DELIVERY_DATE\"), \"yyyy-MM-dd\").isNotNull(),\n",
    "                to_date(col(\"AGREED_DELIVERY_DATE\"), \"yyyy-MM-dd\"),\n",
    "            )\n",
    "            .otherwise(\n",
    "                to_date(lit(\"2024-01-01\"), \"yyyy-MM-dd\")\n",
    "            ),  # Default value for invalid dates\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af5dac9f-21f5-4de8-852e-9c94180cbd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_actual_delivery_date(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and parse ACTUAL_DELIVERY_DATE column.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"ACTUAL_DELIVERY_DATE\"), r\"[^a-zA-Z0-9/,-]\", \"\"\n",
    "            ),  # Remove special characters\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"ACTUAL_DELIVERY_DATE\"), r\"\\d{4}\", \"2024\"\n",
    "            ),  # Replace any year with 2024\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            when(\n",
    "                to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"MM/dd/yyyy\").isNotNull(),\n",
    "                to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"MM/dd/yyyy\"),\n",
    "            )\n",
    "            .when(\n",
    "                to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"yyyy-MM-dd\").isNotNull(),\n",
    "                to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"yyyy-MM-dd\"),\n",
    "            )\n",
    "            .otherwise(\n",
    "                to_date(lit(\"2024-01-01\"), \"yyyy-MM-dd\")\n",
    "            ),  # Default value for invalid dates\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "779f8e13-70dc-4230-8b30-92e1f1d7bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_unwanted_values(df: DataFrame, unwanted_values: list) -> DataFrame:\n",
    "    \"\"\"Filter out rows with unwanted values in any column.\"\"\"\n",
    "    for column in df.columns:\n",
    "        df = df.filter(~trim(col(column)).isin(unwanted_values))\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_null_values(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Drop rows with null values in any column.\"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def convert_column_names_to_lowercase(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Convert column names to lowercase.\"\"\"\n",
    "    return df.select([col(c).alias(c.lower()) for c in df.columns])\n",
    "\n",
    "\n",
    "def add_derived_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Add derived columns for analysis.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"delivery_delay_days\",\n",
    "            datediff(col(\"actual_delivery_date\"), col(\"agreed_delivery_date\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"delivery_completion_rate\",\n",
    "            round(col(\"delivery_qty\") / col(\"order_qty\") * 100, 2),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_on_time\",\n",
    "            when(col(\"delivery_delay_days\") <= 0, \"Yes\").otherwise(\"No\"),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_complete_delivery\",\n",
    "            when(col(\"delivery_completion_rate\") >= 100, \"Yes\").otherwise(\"No\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_order_lines_data(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and transform order lines data.\"\"\"\n",
    "    # Define unwanted values\n",
    "    unwanted_values = [\"NULL\", \"null\", \"NA\", \"none\", \"N/A\"]\n",
    "\n",
    "    # Apply transformations\n",
    "    df = clean_order_id_and_product_id(df)\n",
    "    df = clean_order_qty_and_delivery_qty(df)\n",
    "    df = filter_invalid_quantities(df)\n",
    "    df = clean_agreed_delivery_date(df)\n",
    "    df = clean_actual_delivery_date(df)\n",
    "    df = filter_unwanted_values(df, unwanted_values)\n",
    "    df = drop_null_values(df)\n",
    "    df = convert_column_names_to_lowercase(df)\n",
    "    df = add_derived_columns(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc3f56-fcf8-4ea4-92b9-f899d9884efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load and clean data\n",
    "    order_lines_df = load_order_lines_data(glue_context, s3_input_path)\n",
    "    cleaned_order_lines = clean_order_lines_data(order_lines_df)\n",
    "\n",
    "    # Save the cleaned data to S3 as a CSV file\n",
    "    cleaned_order_lines.write.mode(\"overwrite\").format(\"csv\").option(\n",
    "        \"header\", \"true\"\n",
    "    ).save(s3_output_path)\n",
    "\n",
    "    # Commit the Glue job\n",
    "    job.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192650d8-d3ec-4deb-99b9-335d88745ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data sample:\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "|   ORDER_ID|PRODUCT_ID|ORDER_QTY|AGREED_DELIVERY_DATE|ACTUAL_DELIVERY_DATE|DELIVERY_QTY|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "|FMR34203601|  25891601|    110.0|Friday, March 4, ...|Friday, March 4, ...|         110|\n",
      "|FMR32320302|  25891203|    347.0|Wednesday, March ...|Wednesday, March ...|         347|\n",
      "|FMR33320501|  25891203|    187.0|Thursday, March 3...|Thursday, March 3...|         150|\n",
      "|FMR34220601|  25891203|    235.0|Friday, March 4, ...|Friday, March 4, ...|         235|\n",
      "|FMR33703603|  25891203|    176.0|Thursday, March 3...|Thursday, March 3...|         176|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Cleaned data sample:\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "|   order_id|product_id|order_qty|agreed_delivery_date|actual_delivery_date|delivery_qty|delivery_delay_days|delivery_completion_rate|is_on_time|is_complete_delivery|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "|FMR34203601|  25891601|      110|          2024-01-01|          2024-01-01|         110|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR32320302|  25891203|      347|          2024-01-01|          2024-01-01|         347|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR33320501|  25891203|      187|          2024-01-01|          2024-01-01|         150|                  0|                   80.21|       Yes|                  No|\n",
      "|FMR34220601|  25891203|      235|          2024-01-01|          2024-01-01|         235|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR33703603|  25891203|      176|          2024-01-01|          2024-01-01|         176|                  0|                   100.0|       Yes|                 Yes|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "from pyspark.sql.functions import col, regexp_replace, trim, when, regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, isnan, when, count, date_format, to_date, to_timestamp\n",
    "from pyspark.sql import (\n",
    "    DataFrame,\n",
    "    SparkSession,\n",
    ")\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    datediff,\n",
    "    lit,\n",
    "    regexp_replace,\n",
    "    round,\n",
    "    to_date,\n",
    "    trim,\n",
    "    upper,\n",
    "    when,\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "def clean_order_id_and_product_id(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean ORDER_ID and PRODUCT_ID columns.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"ORDER_ID\",\n",
    "            upper(regexp_replace(trim(col(\"ORDER_ID\")), r\"[^a-zA-Z0-9]\", \"\")),\n",
    "        )\n",
    "        .withColumn(\"PRODUCT_ID\", regexp_replace(col(\"PRODUCT_ID\"), r\"[^0-9]\", \"\"))\n",
    "        .withColumn(\"PRODUCT_ID\", col(\"PRODUCT_ID\").cast(IntegerType()))\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_order_qty_and_delivery_qty(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean ORDER_QTY and DELIVERY_QTY columns.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\"ORDER_QTY\", col(\"ORDER_QTY\").cast(IntegerType()))\n",
    "        .withColumn(\"DELIVERY_QTY\", regexp_replace(col(\"DELIVERY_QTY\"), r\"[^0-9]\", \"\"))\n",
    "        .withColumn(\"DELIVERY_QTY\", col(\"DELIVERY_QTY\").cast(IntegerType()))\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_invalid_quantities(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Filter out rows with invalid quantities.\"\"\"\n",
    "    return df.filter((col(\"ORDER_QTY\") > 0) & (col(\"DELIVERY_QTY\") > 0))\n",
    "\n",
    "\n",
    "def clean_agreed_delivery_date(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and parse AGREED_DELIVERY_DATE column.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"AGREED_DELIVERY_DATE\"), r\",.*$\", \"\"\n",
    "            ),  # Remove comma and anything after it\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"AGREED_DELIVERY_DATE\"), r\"[^a-zA-Z0-9/\\-]\", \"\"\n",
    "            ),  # Remove special characters except / and -\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"AGREED_DELIVERY_DATE\"), r\"\\d{4}\", \"2024\"\n",
    "            ),  # Replace any year with 2024\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            when(\n",
    "                to_date(col(\"AGREED_DELIVERY_DATE\"), \"MM/dd/yyyy\").isNotNull(),\n",
    "                to_date(col(\"AGREED_DELIVERY_DATE\"), \"MM/dd/yyyy\"),\n",
    "            )\n",
    "            .when(\n",
    "                to_date(col(\"AGREED_DELIVERY_DATE\"), \"yyyy-MM-dd\").isNotNull(),\n",
    "                to_date(col(\"AGREED_DELIVERY_DATE\"), \"yyyy-MM-dd\"),\n",
    "            )\n",
    "            .otherwise(\n",
    "                to_date(lit(\"2024-01-01\"), \"yyyy-MM-dd\")\n",
    "            ),  # Default value for invalid dates\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_actual_delivery_date(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and parse ACTUAL_DELIVERY_DATE column.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"ACTUAL_DELIVERY_DATE\"), r\",.*$\", \"\"\n",
    "            ),  # Remove comma and anything after it\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"ACTUAL_DELIVERY_DATE\"), r\"[^a-zA-Z0-9/\\-]\", \"\"\n",
    "            ),  # Remove special characters except / and -\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            regexp_replace(\n",
    "                col(\"ACTUAL_DELIVERY_DATE\"), r\"\\d{4}\", \"2024\"\n",
    "            ),  # Replace any year with 2024\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            when(\n",
    "                to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"MM/dd/yyyy\").isNotNull(),\n",
    "                to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"MM/dd/yyyy\"),\n",
    "            )\n",
    "            .when(\n",
    "                to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"yyyy-MM-dd\").isNotNull(),\n",
    "                to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"yyyy-MM-dd\"),\n",
    "            )\n",
    "            .otherwise(\n",
    "                to_date(lit(\"2024-01-01\"), \"yyyy-MM-dd\")\n",
    "            ),  # Default value for invalid dates\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_unwanted_values(df: DataFrame, unwanted_values: list) -> DataFrame:\n",
    "    \"\"\"Filter out rows with unwanted values in any column.\"\"\"\n",
    "    for column in df.columns:\n",
    "        df = df.filter(~trim(col(column)).isin(unwanted_values))\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_null_values(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Drop rows with null values in any column.\"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def convert_column_names_to_lowercase(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Convert column names to lowercase.\"\"\"\n",
    "    return df.select([col(c).alias(c.lower()) for c in df.columns])\n",
    "\n",
    "\n",
    "def add_derived_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Add derived columns for analysis.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"delivery_delay_days\",\n",
    "            datediff(col(\"actual_delivery_date\"), col(\"agreed_delivery_date\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"delivery_completion_rate\",\n",
    "            round(col(\"delivery_qty\") / col(\"order_qty\") * 100, 2),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_on_time\",\n",
    "            when(col(\"delivery_delay_days\") <= 0, \"Yes\").otherwise(\"No\"),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_complete_delivery\",\n",
    "            when(col(\"delivery_completion_rate\") >= 100, \"Yes\").otherwise(\"No\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_order_lines_data(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and transform order lines data.\"\"\"\n",
    "    # Define unwanted values\n",
    "    unwanted_values = [\"NULL\", \"null\", \"NA\", \"none\", \"N/A\"]\n",
    "\n",
    "    # Apply transformations\n",
    "    df = clean_order_id_and_product_id(df)\n",
    "    df = clean_order_qty_and_delivery_qty(df)\n",
    "    df = filter_invalid_quantities(df)\n",
    "    df = clean_agreed_delivery_date(df)\n",
    "    df = clean_actual_delivery_date(df)\n",
    "    df = filter_unwanted_values(df, unwanted_values)\n",
    "    df = drop_null_values(df)\n",
    "    df = convert_column_names_to_lowercase(df)\n",
    "    df = add_derived_columns(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create Spark Session with legacy time parser policy\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Orderlines DataProcessing\") \\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Define order lines schema\n",
    "    order_lines_schema = StructType(\n",
    "        [\n",
    "            StructField(\"ORDER_ID\", StringType(), True),\n",
    "            StructField(\"PRODUCT_ID\", StringType(), True),\n",
    "            StructField(\"ORDER_QTY\", FloatType(), True),\n",
    "            StructField(\"AGREED_DELIVERY_DATE\", StringType(), True),\n",
    "            StructField(\"ACTUAL_DELIVERY_DATE\", StringType(), True),\n",
    "            StructField(\"DELIVERY_QTY\", StringType(), True),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", True) \\\n",
    "        .schema(order_lines_schema) \\\n",
    "        .load(\"../data/order_lines.csv\")\n",
    "    \n",
    "    # Show sample of original data\n",
    "    print(\"Original data sample:\")\n",
    "    df.show(5)\n",
    "    \n",
    "    # Clean the data\n",
    "    cleaned_df = clean_order_lines_data(df)\n",
    "    \n",
    "    # Show sample of cleaned data\n",
    "    print(\"Cleaned data sample:\")\n",
    "    cleaned_df.show(5)\n",
    "    \n",
    "    # Save cleaned data as CSV\n",
    "    cleaned_df.write \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(\"../data/cleaned_order_lines\")\n",
    "    \n",
    "    # Stop Spark session\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02d3af83-fd43-49ea-9c1a-3e469577fb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/18 20:23:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "Original data sample:\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "|   ORDER_ID|PRODUCT_ID|ORDER_QTY|AGREED_DELIVERY_DATE|ACTUAL_DELIVERY_DATE|DELIVERY_QTY|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "|FMR34203601|  25891601|    110.0|Friday, March 4, ...|Friday, March 4, ...|         110|\n",
      "|FMR32320302|  25891203|    347.0|Wednesday, March ...|Wednesday, March ...|         347|\n",
      "|FMR33320501|  25891203|    187.0|Thursday, March 3...|Thursday, March 3...|         150|\n",
      "|FMR34220601|  25891203|    235.0|Friday, March 4, ...|Friday, March 4, ...|         235|\n",
      "|FMR33703603|  25891203|    176.0|Thursday, March 3...|Thursday, March 3...|         176|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Cleaned data sample:\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "|   order_id|product_id|order_qty|agreed_delivery_date|actual_delivery_date|delivery_qty|delivery_delay_days|delivery_completion_rate|is_on_time|is_complete_delivery|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "|FMR34203601|  25891601|      110|          2022-03-04|          2022-03-04|         110|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR32320302|  25891203|      347|          2022-03-02|          2022-03-02|         347|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR33320501|  25891203|      187|          2022-03-03|          2022-03-03|         150|                  0|                   80.21|       Yes|                  No|\n",
      "|FMR34220601|  25891203|      235|          2022-03-04|          2022-03-04|         235|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR33703603|  25891203|      176|          2022-03-03|          2022-03-03|         176|                  0|                   100.0|       Yes|                 Yes|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "from pyspark.sql.functions import col, regexp_replace, trim, when, regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, isnan, when, count, date_format, to_date, to_timestamp\n",
    "from pyspark.sql import (\n",
    "    DataFrame,\n",
    "    SparkSession,\n",
    ")\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    datediff,\n",
    "    lit,\n",
    "    regexp_replace,\n",
    "    regexp_extract,\n",
    "    round,\n",
    "    to_date,\n",
    "    trim,\n",
    "    upper,\n",
    "    when,\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "def clean_order_id_and_product_id(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean ORDER_ID and PRODUCT_ID columns.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"ORDER_ID\",\n",
    "            upper(regexp_replace(trim(col(\"ORDER_ID\")), r\"[^a-zA-Z0-9]\", \"\")),\n",
    "        )\n",
    "        .withColumn(\"PRODUCT_ID\", regexp_replace(col(\"PRODUCT_ID\"), r\"[^0-9]\", \"\"))\n",
    "        .withColumn(\"PRODUCT_ID\", col(\"PRODUCT_ID\").cast(IntegerType()))\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_order_qty_and_delivery_qty(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean ORDER_QTY and DELIVERY_QTY columns.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\"ORDER_QTY\", col(\"ORDER_QTY\").cast(IntegerType()))\n",
    "        .withColumn(\"DELIVERY_QTY\", regexp_replace(col(\"DELIVERY_QTY\"), r\"[^0-9]\", \"\"))\n",
    "        .withColumn(\"DELIVERY_QTY\", col(\"DELIVERY_QTY\").cast(IntegerType()))\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_invalid_quantities(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Filter out rows with invalid quantities.\"\"\"\n",
    "    return df.filter((col(\"ORDER_QTY\") > 0) & (col(\"DELIVERY_QTY\") > 0))\n",
    "\n",
    "\n",
    "def clean_agreed_delivery_date(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and parse AGREED_DELIVERY_DATE column.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            # Extract the month day, year part\n",
    "            regexp_extract(col(\"AGREED_DELIVERY_DATE\"), r\"([A-Za-z]+, [A-Za-z]+ \\d+, \\d{4})\", 1)\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            to_date(col(\"AGREED_DELIVERY_DATE\"), \"EEEE, MMMM d, yyyy\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_actual_delivery_date(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and parse ACTUAL_DELIVERY_DATE column.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            # Extract the month day, year part\n",
    "            regexp_extract(col(\"ACTUAL_DELIVERY_DATE\"), r\"([A-Za-z]+, [A-Za-z]+ \\d+, \\d{4})\", 1)\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"EEEE, MMMM d, yyyy\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_unwanted_values(df: DataFrame, unwanted_values: list) -> DataFrame:\n",
    "    \"\"\"Filter out rows with unwanted values in any column.\"\"\"\n",
    "    for column in df.columns:\n",
    "        df = df.filter(~trim(col(column)).isin(unwanted_values))\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_null_values(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Drop rows with null values in any column.\"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def convert_column_names_to_lowercase(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Convert column names to lowercase.\"\"\"\n",
    "    return df.select([col(c).alias(c.lower()) for c in df.columns])\n",
    "\n",
    "\n",
    "def add_derived_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Add derived columns for analysis.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"delivery_delay_days\",\n",
    "            datediff(col(\"actual_delivery_date\"), col(\"agreed_delivery_date\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"delivery_completion_rate\",\n",
    "            round(col(\"delivery_qty\") / col(\"order_qty\") * 100, 2),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_on_time\",\n",
    "            when(col(\"delivery_delay_days\") <= 0, \"Yes\").otherwise(\"No\"),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_complete_delivery\",\n",
    "            when(col(\"delivery_completion_rate\") >= 100, \"Yes\").otherwise(\"No\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_order_lines_data(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and transform order lines data.\"\"\"\n",
    "    # Define unwanted values\n",
    "    unwanted_values = [\"NULL\", \"null\", \"NA\", \"none\", \"N/A\"]\n",
    "\n",
    "    # Apply transformations\n",
    "    df = clean_order_id_and_product_id(df)\n",
    "    df = clean_order_qty_and_delivery_qty(df)\n",
    "    df = filter_invalid_quantities(df)\n",
    "    df = clean_agreed_delivery_date(df)\n",
    "    df = clean_actual_delivery_date(df)\n",
    "    df = filter_unwanted_values(df, unwanted_values)\n",
    "    df = drop_null_values(df)\n",
    "    df = convert_column_names_to_lowercase(df)\n",
    "    df = add_derived_columns(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create Spark Session with legacy time parser policy\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Orderlines DataProcessing\") \\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Define order lines schema\n",
    "    order_lines_schema = StructType(\n",
    "        [\n",
    "            StructField(\"ORDER_ID\", StringType(), True),\n",
    "            StructField(\"PRODUCT_ID\", StringType(), True),\n",
    "            StructField(\"ORDER_QTY\", FloatType(), True),\n",
    "            StructField(\"AGREED_DELIVERY_DATE\", StringType(), True),\n",
    "            StructField(\"ACTUAL_DELIVERY_DATE\", StringType(), True),\n",
    "            StructField(\"DELIVERY_QTY\", StringType(), True),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", True) \\\n",
    "        .schema(order_lines_schema) \\\n",
    "        .load(\"../data/order_lines.csv\")\n",
    "    \n",
    "    # Show sample of original data\n",
    "    print(\"Original data sample:\")\n",
    "    df.show(5)\n",
    "    \n",
    "    # Clean the data\n",
    "    cleaned_df = clean_order_lines_data(df)\n",
    "    \n",
    "    # Show sample of cleaned data\n",
    "    print(\"Cleaned data sample:\")\n",
    "    cleaned_df.show(5)\n",
    "    \n",
    "    # Save cleaned data as CSV\n",
    "    cleaned_df.write \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(\"../data/cleaned_order_lines\")\n",
    "    \n",
    "    # Stop Spark session\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b1907d7-a96c-4787-8fb9-03512d845b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/18 20:27:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "Original data sample:\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "|   ORDER_ID|PRODUCT_ID|ORDER_QTY|AGREED_DELIVERY_DATE|ACTUAL_DELIVERY_DATE|DELIVERY_QTY|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "|FMR34203601|  25891601|    110.0|Friday, March 4, ...|Friday, March 4, ...|         110|\n",
      "|FMR32320302|  25891203|    347.0|Wednesday, March ...|Wednesday, March ...|         347|\n",
      "|FMR33320501|  25891203|    187.0|Thursday, March 3...|Thursday, March 3...|         150|\n",
      "|FMR34220601|  25891203|    235.0|Friday, March 4, ...|Friday, March 4, ...|         235|\n",
      "|FMR33703603|  25891203|    176.0|Thursday, March 3...|Thursday, March 3...|         176|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Cleaned data sample:\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "|   order_id|product_id|order_qty|agreed_delivery_date|actual_delivery_date|delivery_qty|delivery_delay_days|delivery_completion_rate|is_on_time|is_complete_delivery|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "|FMR34203601|  25891601|      110|          2024-03-04|          2024-03-04|         110|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR32320302|  25891203|      347|          2024-03-02|          2024-03-02|         347|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR33320501|  25891203|      187|          2024-03-03|          2024-03-03|         150|                  0|                   80.21|       Yes|                  No|\n",
      "|FMR34220601|  25891203|      235|          2024-03-04|          2024-03-04|         235|                  0|                   100.0|       Yes|                 Yes|\n",
      "|FMR33703603|  25891203|      176|          2024-03-03|          2024-03-03|         176|                  0|                   100.0|       Yes|                 Yes|\n",
      "+-----------+----------+---------+--------------------+--------------------+------------+-------------------+------------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "from pyspark.sql.functions import col, regexp_replace, trim, when, regexp_extract\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, isnan, when, count, date_format, to_date, to_timestamp\n",
    "from pyspark.sql import (\n",
    "    DataFrame,\n",
    "    SparkSession,\n",
    ")\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    concat,\n",
    "    datediff,\n",
    "    lit,\n",
    "    lpad,\n",
    "    regexp_replace,\n",
    "    regexp_extract,\n",
    "    round,\n",
    "    to_date,\n",
    "    trim,\n",
    "    upper,\n",
    "    when,\n",
    "    year,\n",
    "    month,\n",
    "    dayofmonth,\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "def clean_order_id_and_product_id(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean ORDER_ID and PRODUCT_ID columns.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"ORDER_ID\",\n",
    "            upper(regexp_replace(trim(col(\"ORDER_ID\")), r\"[^a-zA-Z0-9]\", \"\")),\n",
    "        )\n",
    "        .withColumn(\"PRODUCT_ID\", regexp_replace(col(\"PRODUCT_ID\"), r\"[^0-9]\", \"\"))\n",
    "        .withColumn(\"PRODUCT_ID\", col(\"PRODUCT_ID\").cast(IntegerType()))\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_order_qty_and_delivery_qty(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean ORDER_QTY and DELIVERY_QTY columns.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\"ORDER_QTY\", col(\"ORDER_QTY\").cast(IntegerType()))\n",
    "        .withColumn(\"DELIVERY_QTY\", regexp_replace(col(\"DELIVERY_QTY\"), r\"[^0-9]\", \"\"))\n",
    "        .withColumn(\"DELIVERY_QTY\", col(\"DELIVERY_QTY\").cast(IntegerType()))\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_invalid_quantities(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Filter out rows with invalid quantities.\"\"\"\n",
    "    return df.filter((col(\"ORDER_QTY\") > 0) & (col(\"DELIVERY_QTY\") > 0))\n",
    "\n",
    "\n",
    "def clean_agreed_delivery_date(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and parse AGREED_DELIVERY_DATE column, setting all years to 2024.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            # Extract the month day, year part\n",
    "            regexp_extract(col(\"AGREED_DELIVERY_DATE\"), r\"([A-Za-z]+, [A-Za-z]+ \\d+, \\d{4})\", 1)\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            to_date(col(\"AGREED_DELIVERY_DATE\"), \"EEEE, MMMM d, yyyy\")\n",
    "        )\n",
    "        # Extract month and day, then reconstruct with year 2024\n",
    "        .withColumn(\n",
    "            \"AGREED_DELIVERY_DATE\",\n",
    "            to_date(\n",
    "                concat(\n",
    "                    lit(\"2024-\"),\n",
    "                    lpad(month(col(\"AGREED_DELIVERY_DATE\")).cast(\"string\"), 2, \"0\"),\n",
    "                    lit(\"-\"),\n",
    "                    lpad(dayofmonth(col(\"AGREED_DELIVERY_DATE\")).cast(\"string\"), 2, \"0\")\n",
    "                ),\n",
    "                \"yyyy-MM-dd\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_actual_delivery_date(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and parse ACTUAL_DELIVERY_DATE column, setting all years to 2024.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            # Extract the month day, year part\n",
    "            regexp_extract(col(\"ACTUAL_DELIVERY_DATE\"), r\"([A-Za-z]+, [A-Za-z]+ \\d+, \\d{4})\", 1)\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            to_date(col(\"ACTUAL_DELIVERY_DATE\"), \"EEEE, MMMM d, yyyy\")\n",
    "        )\n",
    "        # Extract month and day, then reconstruct with year 2024\n",
    "        .withColumn(\n",
    "            \"ACTUAL_DELIVERY_DATE\",\n",
    "            to_date(\n",
    "                concat(\n",
    "                    lit(\"2024-\"),\n",
    "                    lpad(month(col(\"ACTUAL_DELIVERY_DATE\")).cast(\"string\"), 2, \"0\"),\n",
    "                    lit(\"-\"),\n",
    "                    lpad(dayofmonth(col(\"ACTUAL_DELIVERY_DATE\")).cast(\"string\"), 2, \"0\")\n",
    "                ),\n",
    "                \"yyyy-MM-dd\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_unwanted_values(df: DataFrame, unwanted_values: list) -> DataFrame:\n",
    "    \"\"\"Filter out rows with unwanted values in any column.\"\"\"\n",
    "    for column in df.columns:\n",
    "        df = df.filter(~trim(col(column)).isin(unwanted_values))\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_null_values(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Drop rows with null values in any column.\"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "def convert_column_names_to_lowercase(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Convert column names to lowercase.\"\"\"\n",
    "    return df.select([col(c).alias(c.lower()) for c in df.columns])\n",
    "\n",
    "\n",
    "def add_derived_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Add derived columns for analysis.\"\"\"\n",
    "    return (\n",
    "        df.withColumn(\n",
    "            \"delivery_delay_days\",\n",
    "            datediff(col(\"actual_delivery_date\"), col(\"agreed_delivery_date\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"delivery_completion_rate\",\n",
    "            round(col(\"delivery_qty\") / col(\"order_qty\") * 100, 2),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_on_time\",\n",
    "            when(col(\"delivery_delay_days\") <= 0, \"Yes\").otherwise(\"No\"),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"is_complete_delivery\",\n",
    "            when(col(\"delivery_completion_rate\") >= 100, \"Yes\").otherwise(\"No\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_order_lines_data(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and transform order lines data.\"\"\"\n",
    "    # Define unwanted values\n",
    "    unwanted_values = [\"NULL\", \"null\", \"NA\", \"none\", \"N/A\"]\n",
    "\n",
    "    # Apply transformations\n",
    "    df = clean_order_id_and_product_id(df)\n",
    "    df = clean_order_qty_and_delivery_qty(df)\n",
    "    df = filter_invalid_quantities(df)\n",
    "    df = clean_agreed_delivery_date(df)\n",
    "    df = clean_actual_delivery_date(df)\n",
    "    df = filter_unwanted_values(df, unwanted_values)\n",
    "    df = drop_null_values(df)\n",
    "    df = convert_column_names_to_lowercase(df)\n",
    "    df = add_derived_columns(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create Spark Session with legacy time parser policy\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Orderlines DataProcessing\") \\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Define order lines schema\n",
    "    order_lines_schema = StructType(\n",
    "        [\n",
    "            StructField(\"ORDER_ID\", StringType(), True),\n",
    "            StructField(\"PRODUCT_ID\", StringType(), True),\n",
    "            StructField(\"ORDER_QTY\", FloatType(), True),\n",
    "            StructField(\"AGREED_DELIVERY_DATE\", StringType(), True),\n",
    "            StructField(\"ACTUAL_DELIVERY_DATE\", StringType(), True),\n",
    "            StructField(\"DELIVERY_QTY\", StringType(), True),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", True) \\\n",
    "        .schema(order_lines_schema) \\\n",
    "        .load(\"../data/order_lines.csv\")\n",
    "    \n",
    "    # Show sample of original data\n",
    "    print(\"Original data sample:\")\n",
    "    df.show(5)\n",
    "    \n",
    "    # Clean the data\n",
    "    cleaned_df = clean_order_lines_data(df)\n",
    "    \n",
    "    # Show sample of cleaned data\n",
    "    print(\"Cleaned data sample:\")\n",
    "    cleaned_df.show(5)\n",
    "    \n",
    "    # Save cleaned data as CSV\n",
    "    cleaned_df.write \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(\"../data/cleaned_order_lines\")\n",
    "    \n",
    "    # Stop Spark session\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698bad5-4656-4554-8127-24acd0b1f313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
